---
title: 'BLIP详解'
date: 2024-09-26
permalink: /posts/2024/09/dl-6/
tags:
  - 多模态模型
  - BLIP
  - 模型架构
---

BLIP是对CLIP模型的改进，BLIP模型被大量使用于多模态工具之中。

## 一、模型结构 ##

<div align=center><img src="https://sheehan-fang.github.io/images/picture/BLIP/3.png"/></div>

模型可以分为三个部分，分别为：对比学习图像文本匹配、二分类图像文本细粒度匹配和生产文本描述。

1. ### 对比学习图像文本匹配 ###

   该部分由一个视觉编码器和一个文本编码器组成。视觉编码器选用的是ViT（Vision Transformer），文本编码器选用的是BERT。两个单模态编码器在完成编码以后，会基于ITC损失进行对比学习，使得文本和图像进一步匹配。

2. ### 二分类图像文本细粒度匹配 ###

   该部分相当于一个二分类编码器。该模块是多模态编码器，对于一些对比学习无法学习到的内容，会在此模块中会进一步进行学习。

3. ### 生产文本描述 ###

   使用解码器来生成与图片相关的文本。相比于之前的模块，该模块使用了Causal Self-Attention，原因是：在生成文本的时候，需要对未生成的部分进行mask，以保证生成的结果正确。

## 二、损失函数 ##

1. ### 对比学习损失	ITC Loss ###

   <div align=center><img src="https://sheehan-fang.github.io/images/picture/BLIP/1.png"/></div>

2. ### 二元损失分类函数 	ITM Loss ###

   <div align=center><img src="https://sheehan-fang.github.io/images/picture/BLIP/2.png"/></div>

3. ### 语言建模损失函数	LM Loss ###

   交叉熵代价函数以自回归的方式最大化文本概率。

