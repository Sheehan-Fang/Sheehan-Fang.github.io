---
title: ' REVEAL：利用多源多模态知识记忆进行检索增强型视觉语言预训练'
date: 2025-2-21
permalink: /posts/2025/02/dl-8/
tags:
  - 深度学习
  - 大模型RAG
  - 多模态
---
本文提出了一种端到端检索增强视觉语言模型（REVEAL），它可以学习将世界知识编码到大规模存储器中，并从中检索以回答知识密集型查询。REV EAL 由四个关键部分组成：存储器、编码器、检索器和生成器。大规模存储器通过一个统一的编码器对各种来源的多模态世界知识（如图像-文本对、问题解答对、知识图谱三元组等）进行编码。检索器在存储器中找到最相关的知识条目，生成器将检索到的知识与输入的查询融合，从而产生输出。我们的方法的一个主要创新点是，存储器、编码器、检索器和生成器都是在海量数据上进行端到端预训练的。此外，我们的方法还可以使用多种多模态知识源，这将带来显著的收益。我们的研究表明，REVEAL 在视觉问题解答和图像字幕方面取得了一流的成果。

### 一、研究背景 ###

1. **现存方法存在的问题**
   - 大规模多模态模型在图像字幕、视觉问题解答和开放词汇识别等下游任务中取得了最先进的结果。然而，这些模型也有一些缺点：**需要大规模的数据和参数计算；**以及，**每次更新知识时都需要重新训练。**
   - 训练多模态检索器时，由于**缺乏直接监督**，没有较好的方法判断哪些知识条目对回答问题最有帮助。
   - 一些现有的方法提出通过独立评估每个检索结果来进行训练。但这种方法**效率低下**，因为它需要独立估计数百个检索到的知识条目，并且**不准确**，因为它忽略了检索集之中不同知识条目之间的依赖关系。
2. **解决上述问题的方法**
   - 让模型学会如何**利用外部知识来源**，用来回答知识密集型查询。
   - 将各种来源的多模态世界知识**编码并存储到一个统一的存储器中**，检索器可以通过多模态查询编码访问该存储器。
   - 通过引入一个注重融合层，**在同时考虑多个检索到的知识条目的情况下获取训练得分**，该层将检索得分注入到注意力计算过程中。

### 二、相关工作 ###

1. **基于知识的视觉问答**
   - **基于知识的视觉问答数据集：**
     - **KB-VQA、FVQA**：通过检索知识图谱中的相关三元组来回答。
     - **OK-VQA**：通过使用外部知识来回答，这些外部知识超出了在输入图像中可观察到的内容。
     - **A-OKQVA：**既需要外部知识又需要关于图像场景的常识推理的问题。
   - **将外部知识纳入视觉语言模型的方法**
     - 利用**结构化知识图谱**或**非结构化文本语料库**中的显性知识进行视觉问答。这些研究的关键部件是**知识检索器**。通常采用已有的视觉模型为图像**生成用于检索的图像标签**或是通过**远距离监督**、**辅助任务**（如实体对齐）来训练检索模型。
     - 利用已有的多模态大模型将**图像转化为文本**，以便问答时检索结果。
2. **检索增强模型的端到端训练**
   - **REALM 、EMDR2：**通过将每个检索结果与查询连接起来来训练单文档检索器，从而独立计算最终损失。
   - **FIDKD：**使用生成器计算出的聚合注意力分数作为提炼信号来训练检索器。
   - **Atlas：**引入了复杂度蒸馏损失和留空变体。

### 三、方法 ###
<div align=center><img src="https://sheehan-fang.github.io/images/picture/REVEAL/5.png"/></div>
REVEAL方法总共分为4个步骤：知识编码、记忆检索和生成。我们假设输入的问题文本为$x$，那么可以在知识库中检索到最相关的$K$个条目，记作$M={m_1, … ,m_K}$。检索的过程可以记作$p(M|x)$，基于检索进行生成的过程可以记作$p(y|x,M)$。那么生成过程$p(y|x)$可以表示为：
$$
p(y|x) = \sum_{M \subset \tilde{M}} p(M | x) \cdot p(y | x, M)
$$

1. **查询编码**

   <div align=center><img src="https://sheehan-fang.github.io/images/picture/REVEAL/1.png"/></div>

   每一个询问将被转化为查询和嵌入的形式。

   - **嵌入的生成：**在对文本进行查询编码时，使用的是下层T5模型；在对图像进行查询编码时，使用的是Vit模型。将编码后的文本向量与图像向量进行拼接，得到值向量。
   - **查询的生成：**将值向量输入到T5模型的上层中，使用Q矩阵和K矩阵来计算查询向量和记忆键。取第一个 [CLS] 令牌的输出，随后进行线性投影和 L2 规范化，以将输入总结为一个d维向量。

2. **记忆**

   <div align=center><img src="https://sheehan-fang.github.io/images/picture/REVEAL/2.png"/></div>

   - **知识库的构建：**该方法使用了多种多模态知识库，包括：文本、图像和图文对数据。
   - **知识项的编码：**每个知识项 ( z ) 被编码为一个键值对 $( m_i = (\text{EmbKey}(z_i), \text{EmbValue}(z_i)) )$。
     - 键的生成：使用 **Key Head**（基于上层的T5模块）将知识项编码为一个d维向量。
     - 值的生成：使用 **Value Head**（基于Perceiver架构）将知识项的完整信息编码为一个压缩的序列嵌入Perceiver通过一个可学习的c维潜在嵌入序列，将完整的token序列压缩为固定长度的c（实验中使用c=32）。这种压缩方式使得可以检索到较大的K值（如K=100）。
   - **记忆的压缩与存储：**为了避免存储大量token带来的开销问题，作者提出了使用Perceiver架构来压缩知识项的值。压缩后的值表示为 $( \text{EmbValue}(z) = \psi(b(z)) \in \mathbb{R}^{c \times d} )$。为了提升压缩表示的表达能力，作者引入了两种正则化方法：
     - **解纠缠正则化**：迫使输出的每个token之间线性去相关。
     - **对齐正则化**：最小化查询和压缩知识嵌入之间的L2范数距离，即$ ( L_{\text{align}} = 1 - \frac{| \psi(b(z)) |_2}{| b(x) |_2} )$。

   

3. **检索**

   <div align=center><img src="https://sheehan-fang.github.io/images/picture/REVEAL/3.png"/></div>

   对于检索任务，假定输入的查询为$x$，top-K实体为$M$，检索数据库$\tilde{M}$由$|\tilde{C}|$个子数据库组成，即$\tilde{M} = [M^1,M^2,...,M^{|\tilde{C}|}]$那么查询过程可以表示为：
   $$
   p(M \mid x) = \prod_{M^j \subset \tilde{M}} p(M^j \mid x)\\
   p(M^j \mid x) = \prod_{m_i^j \in M^j} p(m_i^j \mid x)\\
   p(m_j^i \mid x) = p(M_j \mid x) \cdot p(m_j^i \mid x; M_j)
   \tag{2} \\= \mathrm{Gate}_{M_j}(x) \cdot \frac{\exp\left(\frac{\mathrm{Rel}(x, m_j^i)}{\tau}\right)}{\sum_{m_j^k \in M_j} \exp\left(\frac{\mathrm{Rel}(x, m_j^k)}{\tau}\right)}
   $$
   其中，$\mathrm{Gate}_{M^j}(x) = \mathrm{Softmax}\Big(W \cdot \mathrm{Emb_Query}(x) + b\Big)[j]$,$W$和$b$是超参数，$\mathrm{Emb_Query}(x)$是查询编码过程中生成的查询。

   <div align=center><img src="https://sheehan-fang.github.io/images/picture/REVEAL/6.png"/></div>

   相关性计算可以参考上面的图示$\mathrm{Rel}(x, m_i^j)=\mathrm{Emb_Query}(x)^T·\mathrm{Emb_Key}(z_i^j)$，其中$z_i^j$是数据库中与询问$x$相关的知识项。$\tau$是温度系数。

   此外，还有还从头开始对一小部分（即 10%）检索到的知识条目进行重新编码的过程（红线所示）。通过这种方式，只需适度的计算成本就能更新记忆编码器。

4. **生成**

<div align=center><img src="https://sheehan-fang.github.io/images/picture/REVEAL/4.png"/></div>

   Perceiver是一种Transformer架构的变体，通常用于处理大量输入数据，比如图像或序列，通过将其压缩成更短的序列来降低计算复杂度。这可能涉及到将每个知识项的嵌入进行处理，生成更紧凑的表示。利用Perceiver模块作为头值将Top-K知识和问题压缩成一个短序列后拼接，再将其放入T5-Decode之中得到结果。
